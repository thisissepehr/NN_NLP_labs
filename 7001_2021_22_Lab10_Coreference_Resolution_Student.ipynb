{"cells":[{"cell_type":"markdown","metadata":{"id":"zjmcBKBxDmTI"},"source":["#**Lab 10 - Coreference Resolution**\n","\n","\n","In this lab, we are going to build a coreference system based on the mention-ranking algorithm proposed by Lee et al (2017).  You will get part of the code required to build the system, and you are required to fill three code blocks. Hints will be provided to guide you through. \n","\n","The first part of the notebook will show how to apply coreference resolution to English using a few examples. Then you have to apply that to Arabic.  \n","\n","In total, you will be given one python file (*.py), three JSON files (*.jsonlines) and one embedding file (*.txt):\n","\n","*   **metric.py**: is used to compute the CoNLL scores; you don’t need to change it.\n","*   **[train/test/dev].arabic.jsonlines** Arabic documents are the training, testing and development set will be used for training and evaluating the model, which are ready to use. \n","*   **word_embeddings.filtered.txt** is pre-trained 300-dimensional FastText word embeddings. The original file is large, so we‘ve removed all the words that do not appear in the datasets to make it much smaller.\n","\n","These files are contained in the folder coreference_files provided with the lab.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5087,"status":"ok","timestamp":1651148716374,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"5GC3LPkiNGPd","outputId":"66e2974f-2108-4b09-9f59-be3842faa2b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikit-learn==0.22.2\n","  Downloading scikit_learn-0.22.2-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 14.8 MB/s \n","\u001b[?25hInstalling collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","Successfully installed scikit-learn-0.22.2\n"]}],"source":["#installing the correct scikit-learn lib\n","!pip install scikit-learn==0.22.2 --no-deps"]},{"cell_type":"markdown","metadata":{"id":"_-hCv9PEH1xe"},"source":["##**0. Download the files to google colab.**\n","\n","First, we will download coreference resolution files to Colab so we can access the  dataset and the conll scorer.\n","\n","**Important:**\n","\n","The cells in this section might not work if you are working on your local machine. \n","\n","You might have to download the zip file and unzip it. \n","The coref_files.zip link:\n","\n","https://collect.qmul.ac.uk/down?t=5DBIRDID7VO84D2C/4P63FA4B9R6A4LLML77Q21O\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17282,"status":"ok","timestamp":1651148733653,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"XWTboQ-xWFY1","outputId":"42216ace-f39e-481b-b3a2-d2292f5cfb18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive, output\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1651148733654,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"zZuWg-klXULM","outputId":"542d20a1-906e-4008-dca9-24fa05201407"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: url_coref=https://collect.qmul.ac.uk/down?t=5DBIRDID7VO84D2C/4P63FA4B9R6A4LLML77Q21O\n"]}],"source":["#Setting the URL link for the coreference files\n","%env url_coref=https://collect.qmul.ac.uk/down?t=5DBIRDID7VO84D2C/4P63FA4B9R6A4LLML77Q21O\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1651148734056,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"QFEDSCHySd_0","outputId":"01aecc6a-6307-433a-a803-cd336b9f51d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-04-28 12:25:33--  https://collect.qmul.ac.uk/down?t=5DBIRDID7VO84D2C/4P63FA4B9R6A4LLML77Q21O\n","Resolving collect.qmul.ac.uk (collect.qmul.ac.uk)... 161.23.16.251\n","Connecting to collect.qmul.ac.uk (collect.qmul.ac.uk)|161.23.16.251|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘coref_files.zip’\n","\n","coref_files.zip         [ <=>                ]   2.92K  --.-KB/s    in 0s      \n","\n","2022-04-28 12:25:33 (381 MB/s) - ‘coref_files.zip’ saved [2987]\n","\n"]}],"source":["#Downloading the coref_files.zip \n","!wget $url_coref -O coref_files.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"executionInfo":{"elapsed":215,"status":"error","timestamp":1651092867694,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"j17HivY9GzJ7","outputId":"1c2590c5-706c-4b9d-8296-dde79d39cad2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Extracting the zip file.....\n"]},{"ename":"BadZipFile","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a07a45427317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting the zip file.....'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_zip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"]}],"source":["#Extracting the coref_files.zip\n","import zipfile, os\n","path_to_zip_file = '/content/drive/MyDrive/Colab Notebooks/NN&NLP/coref_files_lab10/coref_files.zip'\n","if(os.path.isdir('/content/coref_files')):\n","    print('The coref files have been uploaded already')\n","else:\n","    print('Extracting the zip file.....')\n","    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","        zip_ref.extractall(\"/content/\")"]},{"cell_type":"markdown","metadata":{"id":"QzRk_pjoJX8s"},"source":["##**1. Add relevant paths**\n","\n","Next, we will append the path to the google drive folder containing the forementioned files to google colab.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sE7JjVsfKB7Y"},"outputs":[],"source":["# IMPORTANT change this to the path to your folder. Remember to start from the home directory, 'My Drive'\n","PATH_TO_FOLDER = \"/content/drive/MyDrive/Colab Notebooks/NN&NLP/coref_files_lab10/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGgQCmpUJki_"},"outputs":[],"source":["import sys\n","sys.path.append(PATH_TO_FOLDER)"]},{"cell_type":"markdown","metadata":{"id":"rUADSXAKLoer"},"source":["Now we can also add the paths to our dev/test/train files and our filtered embeddings\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9oagEtOLvLG"},"outputs":[],"source":["DEV_PATH = PATH_TO_FOLDER + 'dev.arabic.jsonlines'\n","TEST_PATH = PATH_TO_FOLDER + 'test.arabic.jsonlines'\n","TRAIN_PATH = PATH_TO_FOLDER + 'train.arabic.jsonlines'\n","\n","EMBEDDING_PATH = PATH_TO_FOLDER + 'word_embeddings.filtered.txt'"]},{"cell_type":"markdown","metadata":{"id":"dOxJXF6rMZDO"},"source":["\n","##**2. Import files**\n","\n","We can now import metrics.py along with other python modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qK_q_BJVMYMz"},"outputs":[],"source":["%%capture\n","\n","from keras import Input,Model\n","from keras import backend as K\n","from keras.layers import Dropout,Dense,LSTM,Bidirectional,Lambda,Reshape\n","import numpy as np\n","import tensorflow as tf \n","import random\n","import json,time,collections,random, metrics\n","\n","#seed everything\n","seed_value = 42\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","tf.random.set_seed(seed_value)"]},{"cell_type":"markdown","metadata":{"id":"YFkp8bcxNq7U"},"source":["## **3. Creating an embedding dictionary**\n","\n","Using the embedding file, we will create an embedding dictionary,\n","for easy access while preparing our data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfFqHWl3Ot08"},"outputs":[],"source":["# the dimension of the pretrained embeddings\n","EMBEDDING_SIZE = 300"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpTTwvYCNplG"},"outputs":[],"source":["def load_embeddings(embedding_path=EMBEDDING_PATH, embedding_size=EMBEDDING_SIZE):\n","    print(\"Loading word embeddings from {}...\".format(embedding_path))\n","    embeddings = collections.defaultdict(lambda: np.zeros(embedding_size))\n","    for line in open(embedding_path):\n","        splitter = line.find(' ')\n","        emb = np.fromstring(line[splitter + 1:], np.float32, sep=' ')\n","        assert len(emb) == embedding_size\n","        embeddings[line[:splitter]] = emb\n","    print(\"Finished loading word embeddings\")\n","    print(\"Number of words: \" + str(len(embeddings)))\n","    return embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2519,"status":"ok","timestamp":1651148739918,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"CY7_Mc3bOyMh","outputId":"d46e3e0c-c338-4082-efb1-1da7a8e65e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading word embeddings from /content/drive/MyDrive/Colab Notebooks/NN&NLP/coref_files_lab10/word_embeddings.filtered.txt...\n","Finished loading word embeddings\n","Number of words: 26546\n"]}],"source":["EMBEDDING_DICT = load_embeddings() "]},{"cell_type":"markdown","metadata":{"id":"q4BgyGNrQnTy"},"source":["##**4. Preparing Documents for Coreference**"]},{"cell_type":"markdown","metadata":{"id":"1xqZA8TxQ2zR"},"source":["In this section,  we will show how to prepare the dataset for coreference resolution using a few examples in English. Then youwill have to prepare for the Arabic dataset in the jsonfiles.\n","<br>\n","\n","Each line in a given json file contains information for a single document. The “doc_key” stores the name of the document; the “sentences” points you to tokenized sentences of the document; the “clusters” element stores the coreference clusters. Each of the clusters contains a number of mentions encoded, each of the mentions has a start and an end indices, denoting the position of its first token and the index its last token within the document. \n","As an illustration, consider the dummy dataset in the block of code below containing one document. Run the code cell to see the clusters of coreferent mentions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1651148739918,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"IK_Clal1RL5g","outputId":"b27f9a15-caf7-45df-d967-c187669955dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["These are the clusters in large_cat\n","Cluster 0: ['The large cat', 'He', 'he', 'The cat']\n","Cluster 1: ['An unfortunate rat', 'him']\n"]}],"source":["dummy_dataset = [{'doc_key': 'large_cat',\n","                  'sentences':[['The', 'large', 'cat', 'yawned', '.'],\n","                               ['He','was', 'very', 'hungry', 'as', 'he', 'had', 'not', 'eaten', 'since', 'breakfast','.'],\n","                               ['An', 'unfortunate', 'rat', 'came', 'along', '.'],\n","                               ['The', 'cat', 'gobbled', 'him', 'up', '.']],\n","                  'clusters': [[[0, 2], [5, 5], [10, 10], [23, 24]], [[17, 19], [26, 26]]]\n","                }]\n","\n","\n","sents = [w for sent in dummy_dataset[0]['sentences'] for w in sent]\n","print('These are the clusters in %s' %dummy_dataset[0]['doc_key'])\n","for cl_idx, cl in enumerate(dummy_dataset[0]['clusters']):\n","    print('Cluster ' + str(cl_idx) + ':', [' '.join(sents[s: e+1])  for s, e in cl])"]},{"cell_type":"markdown","metadata":{"id":"VR0D0wOlYg_J"},"source":["To prepare the each dataset for the coreference resolution model, we will need to create variables from the each document:\n","\n","1.   Embedded Sentences: A 1 X num_sents X num_words X embedding size array for each document. \n","2.   Mention Pairs: A 1 X num_pairs X 4 array like so [anaphor_start, anaphor_end, antecedent_start, antecedent_end]\n","3. Mention Pair Labels: A num_pairs X 1 array containing corresponding labels for each mention pair (i.e. 1 if the pair of mentions are coreferent, 0 otherwise). \n","\n","The functions that follow in the subsections below contains code for extracting this dataset. Study them and test their functionality using the dummy dataset.\n","In section 4.4, you'll use these functions to create the dev, test and train datasets."]},{"cell_type":"markdown","metadata":{"id":"r1BX3m74VjT9"},"source":["###**4.1 Getting the mentions from the clusters**\n","\n","The following block of code gets the mentions from a given cluster in a document. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUxPZC5LThS8"},"outputs":[],"source":["def get_mentions(clusters):\n","\n","    # get a list of mentions (as tuples) sorted by start indices.\n","    gold_mentions = sorted([tuple(m) for cl in clusters for m in cl])\n","\n","    # number of mentions\n","    num_mentions = len(gold_mentions)\n","\n","    # assign unique indices to each mention in the mention list based on its position in the list\n","    gold_mention_map = {m: i for i, m in enumerate(gold_mentions)}\n","\n","    # assign cluster ids to each mention in order E.g. cluser_ids = [4, 11, 5, 4, ..] => mention 0 is in cluster 4\n","    # along with mention 3.\n","    cluster_ids = [0]*num_mentions\n","    for cid, cluster in enumerate(clusters):\n","        for mention in cluster:\n","            cluster_ids[gold_mention_map[tuple(mention)]] = cid\n","\n","    return gold_mentions, gold_mention_map, cluster_ids, num_mentions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651148739919,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"MpCkYY8xWee6","outputId":"549dd7be-7cf6-4db0-8bc6-0bcf031cfa46"},"outputs":[{"name":"stdout","output_type":"stream","text":["These are all the coreferent mentions in the sample document  [(0, 2), (5, 5), (10, 10), (17, 19), (23, 24), (26, 26)]\n","These are the mentions mapped to unique ids denoting their order in the document  {(0, 2): 0, (5, 5): 1, (10, 10): 2, (17, 19): 3, (23, 24): 4, (26, 26): 5}\n","These are the cluster ids of the ordered mentions [0, 0, 0, 1, 0, 1]\n","There are 6 mentions in the document titled 'large_cat'\n"]}],"source":["dmentions, dment_map, dcluster_ids, dnum_mentions = get_mentions(dummy_dataset[0]['clusters'])\n","print('These are all the coreferent mentions in the sample document ', dmentions)\n","print('These are the mentions mapped to unique ids denoting their order in the document ', dment_map)\n","print('These are the cluster ids of the ordered mentions', dcluster_ids)\n","print('There are %d mentions in the document titled \\'%s\\'' %(dnum_mentions, dummy_dataset[0]['doc_key']))"]},{"cell_type":"markdown","metadata":{"id":"RvrRxjHiX_s8"},"source":["###**4.2 Turning the sentences into embeddings and the mention indices into vectors**\n","\n","Using the next block of code, you can generate the padded document embeddings, and a copy of the mention starts and end indices adjusted for padding. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlOAWoL3Wv0l"},"outputs":[],"source":["def tensorize_doc_sentences(sentences, mentions):\n","    starts, ends = [],[]\n","    sent_lengths = [len(sent) for sent in sentences]  # the actual, unpadded length of each sentence\n","    max_sent_length = max(sent_lengths)\n","\n","    # by padding each sentence to the maximum length, the embedded document will a new dimension\n","    embedded_sentences = np.zeros([1, len(sentences), max_sent_length, EMBEDDING_SIZE])\n","\n","    # in this block, we adjust the mention indices to reflect the added padding.\n","    sent_start = 0\n","    sent_start_after_padding = 0\n","    offset = 0\n","    for i, sent in enumerate(sentences):\n","        for m_start, m_end in mentions:\n","            if (sent_start <= m_start) & (m_end < sent_start + len(sent)):\n","                starts.append(m_start + offset)\n","                ends.append(m_end + offset)\n","        sent_start += len(sent)\n","        sent_start_after_padding += max_sent_length\n","        offset += max_sent_length - len(sent)\n","\n","        # Populate the the embedding tensor with the appropriate word embeddings.\n","        for j, word in enumerate(sent):\n","                embedded_word = EMBEDDING_DICT[word]\n","                embedded_sentences[0, i, j] = embedded_word\n","\n","\n","    return embedded_sentences, starts, ends"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pUm4-blXxpb"},"outputs":[],"source":["dsents_embedded, dstarts, dends = tensorize_doc_sentences(dummy_dataset[0]['sentences'], dmentions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651148739920,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"C40AGj8zYjRk","outputId":"d52dfe58-62a2-48e6-a64c-42ae29c43ccf"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 document with 4 sentences, each with a maximum of 12 words, encoded as 300 dimensional vectors\n","Mention starts:  [0, 12, 17, 24, 36, 39]\n","Mention ends:  [2, 12, 17, 26, 37, 39]\n"]}],"source":["print('%d document with %d sentences, each with a maximum of %d words, encoded as %d dimensional vectors' %(dsents_embedded.shape[0], dsents_embedded.shape[1], dsents_embedded.shape[2], dsents_embedded.shape[3])) \n","print('Mention starts: ', dstarts)\n","print('Mention ends: ', dends)"]},{"cell_type":"markdown","metadata":{"id":"2Ks-fpwFaVOp"},"source":["###**4.3. Generating Mention Pairs**\n","\n","This next function generates the example pairs for training or evaluation. For each mention (anaphor), candidate antecedents are any mentions preceeding it.\n","\n","<br>\n","\n","Here, during training we choose up to 250 antecedents (i.e. MAX_ANT = 250) and maintain a 2:1 negative to positive example ratio i.e. NEG_RATIO=2. (choosing this ratio can be challenging as you want ample examples to learn from but at the same time do not want the positive examples to be overshadowed by the negative ones).\n","\n","<br>\n","\n","At test time, we generate up to MAX_ANT examples without paying attention to the example ratio. We also do not generate training labels for the pairs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1caJxj6maIcn"},"outputs":[],"source":["# the maximum number of candidate antecedents we will give to each of the candidate mentions.\n","MAX_ANT = 250\n","\n","# the ratio of negative to postive examples\n","NEG_RATIO = 5"]},{"cell_type":"markdown","metadata":{"id":"qjP4hwrZlNIj"},"source":["\n","\n","Study the function below and see the sample outputs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ibkw-OMulKF-"},"outputs":[],"source":["def generate_pairs(num_mentions, cluster_ids, starts, ends, raw_starts, raw_ends, is_training, neg_ratio=NEG_RATIO, max_ant=MAX_ANT):\n","    mention_pairs = [[]]\n","    mention_pair_labels = [[]]\n","    raw_mention_pairs = []\n","\n","    # for the training set, we want labels. We also want to pay heed to the positive:negative example ratio\n","    if is_training:\n","        for ana in range(num_mentions):\n","            pos = 1\n","            # each anaphor must not have more that MAX_ANT candidate antecedents\n","            s = 0 if ana < max_ant else (ana - max_ant)\n","            for ant in range(s, ana):\n","                # two mentions are coreferent if they are in the same cluster\n","                l = cluster_ids[ana] == cluster_ids[ant]\n","                # if it's a positive example, add it\n","                if l:\n","                    pos += neg_ratio\n","                    mention_pairs[0].append([starts[ana],ends[ana],starts[ant],ends[ant]])\n","                    mention_pair_labels[0].append(1)\n","                # if it's a negative example, check that we don't already have twice as \n","                # many negative examples as positive ones before adding it\n","                elif pos > 0:\n","                    pos -=1\n","                    mention_pairs[0].append([starts[ana],ends[ana],starts[ant],ends[ant]])\n","                    mention_pair_labels[0].append(0)\n","\n","    # for the test set, add the pairs without balancing or labels\n","    else:\n","        for ana in range(num_mentions):\n","            s = 0 if ana < max_ant else (ana - max_ant)\n","            for ant in range(s,ana):\n","                mention_pairs[0].append([starts[ana], ends[ana], starts[ant], ends[ant]])\n","                # here we also add the original mention indices for unpadded evaluation.\n","                raw_mention_pairs.append([(raw_starts[ana], raw_ends[ana]), (raw_starts[ant], raw_ends[ant])])\n","    \n","\n","    return mention_pairs, mention_pair_labels, raw_mention_pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651148739921,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"8PLwCe5Nxwi2","outputId":"b5a6d744-84bc-43aa-a2bd-aa2988c31019"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ana_Ant pair        Pair label (padded)\n","----------------  ---------------------\n","[12, 12, 0, 2]                        1\n","[17, 17, 0, 2]                        1\n","[17, 17, 12, 12]                      1\n","[24, 26, 0, 2]                        0\n","[36, 37, 0, 2]                        1\n","[36, 37, 12, 12]                      1\n","[36, 37, 17, 17]                      1\n","[36, 37, 24, 26]                      0\n","[39, 39, 12, 12]                      0\n","[39, 39, 24, 26]                      1\n","[39, 39, 36, 37]                      0\n"]}],"source":["# A sample for training. Maximum of 4 antecedents per mention a 2:1 negative example ratio: positive example. No need to save the raw starts/ends\n","dmpairs, dpair_labels, draw_pairs = generate_pairs(dnum_mentions, dcluster_ids, dstarts, dends, None, None, True, 1, 4)\n","\n","from tabulate import tabulate\n","print(tabulate(zip(dmpairs[0], dpair_labels[0]), headers=['Ana_Ant pair', 'Pair label (padded)', ]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1651148739922,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"IrgtEVgLxAme","outputId":"e28a8a65-b847-4fc5-9797-c5af651b6edb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ana_Ant pair (unpadded)    Ana_Ant pair (padded)\n","-------------------------  -----------------------\n","[(5, 5), (0, 2)]           [12, 12, 0, 2]\n","[(10, 10), (0, 2)]         [17, 17, 0, 2]\n","[(10, 10), (5, 5)]         [17, 17, 12, 12]\n","[(17, 19), (0, 2)]         [24, 26, 0, 2]\n","[(17, 19), (5, 5)]         [24, 26, 12, 12]\n","[(17, 19), (10, 10)]       [24, 26, 17, 17]\n","[(23, 24), (0, 2)]         [36, 37, 0, 2]\n","[(23, 24), (5, 5)]         [36, 37, 12, 12]\n","[(23, 24), (10, 10)]       [36, 37, 17, 17]\n","[(23, 24), (17, 19)]       [36, 37, 24, 26]\n","[(26, 26), (0, 2)]         [39, 39, 0, 2]\n","[(26, 26), (5, 5)]         [39, 39, 12, 12]\n","[(26, 26), (10, 10)]       [39, 39, 17, 17]\n","[(26, 26), (17, 19)]       [39, 39, 24, 26]\n","[(26, 26), (23, 24)]       [39, 39, 36, 37]\n"]}],"source":["# A sample for evaluation. No labels necessary. Here we pair each mention with all its antecedents\n","draw_starts, draw_ends = zip(*dmentions)\n","dmpairs, dpair_labels, draw_pairs = generate_pairs(dnum_mentions, dcluster_ids, dstarts, dends, draw_starts, draw_ends, False)\n","\n","from tabulate import tabulate\n","print(tabulate(zip(draw_pairs, dmpairs[0]), headers=['Ana_Ant pair (unpadded)', 'Ana_Ant pair (padded)', ]))"]},{"cell_type":"markdown","metadata":{"id":"0QukrGCo4sVc"},"source":["### **4.4. Preprocessing and loading the dataset**\n","\n","Now, you will prepare the dataset for the coreference resolution model. Preprocessing step is an important step and depends on the target language. For Arabic, removing diacritics (accents that are written  above, below or on top of certain letters)may improve the overall performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0iI7wBh5rUo"},"outputs":[],"source":["import re, json\n","\n","def preprocess_arabic_text(text):\n","  #diacrtic unicodes are found using regular expressions\n","  diacritics_unicode = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n","  #the diacrtics are then removed\n","  text = re.sub(diacritics_unicode, \"\", text)\n","  return text\n","\n","def get_data(json_file, is_training, preprocess_text):\n","    processed_docs = []\n","\n","    for line in open(json_file):\n","\n","      # read the document in\n","      doc = json.loads(line)\n","      \n","      # check that there are coreferent mentions in this document\n","      clusters = doc['clusters']\n","\n","      sentences = doc['sentences']\n","\n","      if(preprocess_text==True):\n","          preprocessed_sents = [[preprocess_arabic_text(t) for t in sent] for sent in sentences]\n","          doc['sentences'] = preprocessed_sents\n","      \n","      if len(clusters) == 0:\n","          continue\n","\n","      #  get the mentions and their cluster information.\n","      gold_mentions, gold_mention_map, cluster_ids, num_mentions =  get_mentions(clusters)# TASK 1.1 YOUR CODE HERE\n","\n","      # splits the mentions into two arrays, one representing the start indices, \n","      # and the other for the end indices\n","      raw_starts, raw_ends = zip(*gold_mentions)\n","\n","      # pad sentences, create glove sentence embeddings, create mention starts and ends for padded document\n","      word_emb, starts, ends = tensorize_doc_sentences(doc['sentences'], gold_mentions) # TASK 1.2 YOUR CODE HERE\n","\n","      # generate (anaphor, antecedent) pairs and their labels\n","      mention_pairs, mention_pair_labels, raw_mention_pairs = generate_pairs(num_mentions, cluster_ids, starts, ends, raw_starts, raw_ends, is_training) # TASK 1.3 YOUR CODE HERE\n","      mention_pairs, mention_pair_labels = np.array(mention_pairs),np.array(mention_pair_labels)\n","\n","      # add the processed document to the list\n","      processed_docs.append((word_emb, mention_pairs, mention_pair_labels, clusters, raw_mention_pairs))\n","\n","    return processed_docs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ky4ukJeB42nA"},"outputs":[],"source":["#get_data(json_file, is_training_preprocess_text) receives three inputs: \n","#json_file (str) : the path to json file, preprocess_text)\n","#is_training (boolean): this is used to with generate_pairs(...) function to balance the number of generated pairs\n","#preprocess_text (boolean): whether to preprocess text or not \n","\n","DEV_DATA = get_data(DEV_PATH, False, True)\n","TEST_DATA = get_data(TEST_PATH, False, True)\n","TRAIN_DATA = get_data(TRAIN_PATH, True, True)"]},{"cell_type":"markdown","metadata":{"id":"8T-yYog5t4iD"},"source":["##**5. Building the Coreference Model**\n","\n","In this section, we will build the coreference resolution model. There are many ways to learn coreference, in this lab, we will be building a simplified version of a mention pair classification model. \n","\n","<br>\n","\n","Given a pair of mentions, (anaphor, antecedent), a mention pair classifier produces a single score between 0 and 1, representing the probability that the given pair is coreferent. We will use keras to take in the processed data we prepared in section 4 and produce mention pair scores for the given pairs."]},{"cell_type":"markdown","metadata":{"id":"GGp8agamJ0gc"},"source":["###**5.1 First, we will initialize model parameters.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmVyZ6XFISdd"},"outputs":[],"source":["# the dimension of the pretrained embeddings\n","EMBEDDING_SIZE = 300\n","\n","# dropout rate for word embeddings\n","EMBEDDING_DROPOUT_RATE = 0.0\n","\n","# the size of the hidden layer, include both LSTM and feedforward NN\n","HIDDEN_SIZE = 50\n","\n","# the number of hidden layers used for the feedforward NN\n","NUM_FFN_LAYER = 2\n","\n","# the dropout rate for the hidden layers of LSTM and feedforward NN\n","HIDDEN_DROPOUT_RATE = 0.2\n"]},{"cell_type":"markdown","metadata":{"id":"KXkdiV0AJ8Sq"},"source":["###**5.2 Building the model**\n","\n","In the next cell block, you will complete the build function by doing completing the steps that follow.\n","\n","1. **Initialize the model inputs**\n","\n","(a.) Using the keras input layer (already imported) initialize the two input layers\n"," `word_embeddings` and `mention_pairs`.\n"," \n","**Hints:**\n","*  The dimension for this input is `(batch_size X num_sents X num_words X embedding_size)` where batch_size is the number of inputs at each time step. Our batch size is 1 document.\n","*  As always, we do not need to specify the batch_size to the model (i.e. the first dimension is not included in the `shape` parameter of `Input()`.\n","*  The shape parameter is thus a tuple of 3 elements `(num_sents, num_words, embedding_size)`. The first two parameters vary accross documents but no matter, keras can infer them. You only need to specify the third (-1) element in the tuple.\n","*  The dimension for this input is  `(batch_size X num_mention_pairs  X 4)`.\n","\n","    A line of code has been written for you to squeeze the word_embeddings after they have been created to remove the document dimension as the LSTMs only take 3 dimensional inputs\n","\n","    `word_embeddings_no_batch = Lambda(lambda x: K.squeeze(x,0))(word_embeddings)`\n","\n","    <br>\n","\n","(b.) Apply `EMBEDDING_DROPOUT_RATE` dropout to this no-batch word embeddings\n","\n","<br>\n","\n","2. **Encode the document using Bidirectional LSTMs**\n","\n","\n","For task 1 we will be working at the beginning of the build() method. The task is to create a bidirectional LSTM to encode the sentences from both directions, which provides context information to the coreference system.\n","\n","**Hints:**\n","* You'll need:\n","The dropout rate  of the hidden layers: `HIDDEN_DROPOUT_RATE`\n","The size of the lstm hidden layers: `HIDDEN_SIZE`\n","\n","* You need to create a two layer bidirectional LSTM (BiLSTMs) by stacking two LSTM() layers wrapped with Bidirectional() layers. The BiLSTMs need to return the output for all the tokens in the sentences, not just the final one. The output of the BiLSTMs should be called word_output. Here is an example of how to create a BiLSTMs using keras: https://keras.io/examples/imdb_bidirectional_lstm/.\n","\n","* Inorder to return the output for all the tokens in the sentences, i.e. a `(num_sents X num_words X HIDDEN_SIZE)` tensor, you will need to set the return_sequences attribute to True. The default setting is to return only the final output of the LSTM. And don’t forget to apply the recurrent_dropout.\n","\n","<br>\n","\n","We then flatten the output of the lstms to get a `(num_sents*num_words X HIDDEN_SIZE)` tensor using the Lambda function. This will help us gather the right indices for the mention pairs. We also apply further dropout.\n","\n","`flatten_word_output = Lambda(lambda x:K.reshape(x, [-1, 2 * HIDDEN_SIZE]))(word_output)`\n","\n","`flatten_word_output = Dropout(HIDDEN_DROPOUT_RATE)(flatten_word_output)`\n","\n","\n","<br>\n","\n","Then, we get the mention pair representations by first collecting the learned embeddings for each the words represented by [anaphor_start, anaphor_end, antecedent_start, antecedent_end] for each pair. We retain the document dimension (i.e. batch_size) for this input.\n","\n","`mention_pair_emb = Lambda(lambda x: K.gather(x[0], x[1]))([flatten_word_output, mention_pairs])`\n","\n","Then concatenating the embeddings such that each mention pair is represented by a `4 X HIDDEN_SIZE` tensor.\n","\n","`ffnn_input = Reshape((-1,8*HIDDEN_SIZE))(mention_pair_emb)`\n","\n","`ffnn_input` is thus a `batch_size X num_mention_pairs X 400` tensor\n","\n","<br>\n","\n","3. **Create a multilayer feed-forward neural network to compute the mention-pair scores.**\n","\n","Then you are required to create a FFNN that contains 2 hidden layers and an output layer. The outputs of the FFNN are  mention_pair_scores. Here are some requirements:\n","\n","The hidden layers need to have a size of `HIDDEN_SIZE`\n","You need to apply dropout after each the hidden layers (but not the output layer). The outputs are called mention_pair_scores\n","\n","**Hint:** \n","\n","Each hidden layer of the FFNN is a simple Dense() with an relu activation function. Layers are simply stacked together the output of the previous layer is the input for the next layer. To apply the dropout you can simply use the Dropout() layer. The output layer is slightly different, since it will have an output size of 1. Also in order to compute the binary cross entropy loss we need to give this final layer a sigmoid activation function.\n","\n","After computing the mention_pair_scores you will need to remove the last dimension of it, since the last dimension is always 1. But be careful this time we will need to retain the batch dimension (for compute the loss and training accuracy). Again you can use the K.squeeze() method wrapped with a Lambda layer.\n","The final output `mention_pair_scores` should be a `batch_size X num_mention_pairs` tensor.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5-NZADY5vGQ"},"outputs":[],"source":["def build_model():\n","    # 1 (a.) Initialize the model inputs\n","    word_embeddings = Input(shape=(None,None,EMBEDDING_SIZE))\n","    mention_pairs = Input(shape=(None,None,4),dtype='int32')\n","\n","    # squeeze the (batch_size X num_sents X num_words X embedding_size) into a \n","    # (num_sents X num_words X embedding_size) tensor\n","    word_embeddings_no_batch = Lambda(lambda x: K.squeeze(x,0))(word_embeddings)\n","\n","    # 1 (b.). Apply embedding dropout to the squeezed embeddings.\n","    word_embeddings_dropped = Dropout(EMBEDDING_DROPOUT_RATE)(word_embeddings_no_batch)\n","\n","    # 2. YOU CREATE A TWO LAYER BIDIRECTIONAL LSTM\n","    word_output = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True, recurrent_dropout=HIDDEN_DROPOUT_RATE))(word_embeddings_dropped)\n","    word_output = Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True, recurrent_dropout=HIDDEN_DROPOUT_RATE))(word_output)\n","\n","    # flattening the lstms output and apply dropout.\n","    flatten_word_output = Lambda(lambda x:K.reshape(x, [-1, 2 * HIDDEN_SIZE]))(word_output)\n","    flatten_word_output = Dropout(HIDDEN_DROPOUT_RATE)(flatten_word_output)\n","\n","    # we gather the embeddings represented by [anaphor_start, anaphor_end, antecedent_start, antecedent_end] for each pair.\n","    mention_pair_emb = Lambda(lambda x: K.gather(x[0], x[1]))([flatten_word_output, mention_pairs])\n","\n","    # we flatten them such that each mention_pair is represented by a 400D tensor.\n","    ffnn_input = Reshape((-1,8*HIDDEN_SIZE))(mention_pair_emb)\n","\n","    # 3. CREATE THE MULTILAYER PERCEPTRONS THEN SQUEEZE OUT THE LAST DIMENSION USING LAMBDA\n","    mention_pair_scores = Dense(HIDDEN_SIZE, activation='relu')(ffnn_input)\n","    mention_pair_scores = Dropout(HIDDEN_DROPOUT_RATE)(mention_pair_scores)\n","    mention_pair_scores = Dense(HIDDEN_SIZE, activation='relu')(mention_pair_scores)\n","    mention_pair_scores = Dropout(HIDDEN_DROPOUT_RATE)(mention_pair_scores)\n","    mention_pair_scores = Dense(1, activation='sigmoid')(mention_pair_scores)\n","    mention_pair_scores = Lambda(lambda x: K.squeeze(x,2))(mention_pair_scores)\n","\n","    model = Model(inputs=[word_embeddings,mention_pairs], outputs=mention_pair_scores)\n","    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n","    print(model.summary())\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4334,"status":"ok","timestamp":1651148749490,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"huNfKPWudNkW","outputId":"e5275cb2-d679-40e7-bdf1-0e43373ea290"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda (Lambda)                (None, None, 300)    0           ['input_1[0][0]']                \n","                                                                                                  \n"," dropout (Dropout)              (None, None, 300)    0           ['lambda[0][0]']                 \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, None, 100)    140400      ['dropout[0][0]']                \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, None, 100)   60400       ['bidirectional[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," lambda_1 (Lambda)              (None, 100)          0           ['bidirectional_1[0][0]']        \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 100)          0           ['lambda_1[0][0]']               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None, None,  0           []                               \n","                                 4)]                                                              \n","                                                                                                  \n"," lambda_2 (Lambda)              (None, None, None,   0           ['dropout_1[0][0]',              \n","                                4, 100)                           'input_2[0][0]']                \n","                                                                                                  \n"," reshape (Reshape)              (None, None, 400)    0           ['lambda_2[0][0]']               \n","                                                                                                  \n"," dense (Dense)                  (None, None, 50)     20050       ['reshape[0][0]']                \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, None, 50)     0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, None, 50)     2550        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, None, 50)     0           ['dense_1[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, None, 1)      51          ['dropout_3[0][0]']              \n","                                                                                                  \n"," lambda_3 (Lambda)              (None, None)         0           ['dense_2[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"]}],"source":["model = build_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1651148749907,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"},"user_tz":-60},"id":"lF84k4zG7E3a","outputId":"911fb08e-ce8b-4a3e-be86-ac347cb75ecd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_4 (Lambda)              (None, None, 300)    0           ['input_3[0][0]']                \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, None, 300)    0           ['lambda_4[0][0]']               \n","                                                                                                  \n"," bidirectional_2 (Bidirectional  (None, None, 100)   140400      ['dropout_4[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," bidirectional_3 (Bidirectional  (None, None, 100)   60400       ['bidirectional_2[0][0]']        \n"," )                                                                                                \n","                                                                                                  \n"," lambda_5 (Lambda)              (None, 100)          0           ['bidirectional_3[0][0]']        \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 100)          0           ['lambda_5[0][0]']               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, None, None,  0           []                               \n","                                 4)]                                                              \n","                                                                                                  \n"," lambda_6 (Lambda)              (None, None, None,   0           ['dropout_5[0][0]',              \n","                                4, 100)                           'input_4[0][0]']                \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, None, 400)    0           ['lambda_6[0][0]']               \n","                                                                                                  \n"," dense_3 (Dense)                (None, None, 50)     20050       ['reshape_1[0][0]']              \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, None, 50)     0           ['dense_3[0][0]']                \n","                                                                                                  \n"," dense_4 (Dense)                (None, None, 50)     2550        ['dropout_6[0][0]']              \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, None, 50)     0           ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, None, 1)      51          ['dropout_7[0][0]']              \n","                                                                                                  \n"," lambda_7 (Lambda)              (None, None)         0           ['dense_5[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"]}],"source":["model = build_model()"]},{"cell_type":"markdown","metadata":{"id":"kvzxGGeBvSme"},"source":["##**6. Coreference Resolution Evaluation**\n","\n","Coreference Resolution models are not evaluated using regular accuracy or f1 as one would evaluate a text classification model. Rather, using the pairwise scores produced by the system, we build coreference clusters. These clusters are\n","then evaluated using the CONLL score https://www.aclweb.org/anthology/W12-4501/ \n","In this section, we build functions to build such clusters."]},{"cell_type":"markdown","metadata":{"id":"dp0Db-2424KT"},"source":["###**6.1 Getting the Predicted clusters**\n","\n","First, we will write a function that takes a pair of mentions and produces two variables:\n","\n","1. `predicted_clusters`: a list of tuples. Each tuple is a cluster (i.e. the elements of each tuple are the mentions predicted to belong to that cluster, where each mention is a (start_index, end_index) tuple.\n","\n","2. `mention_to_predicted`: a dictionary whose keys are mentions and whose values are predicted clusters for the given mention\n","\n","The input to the function `mention_pairs` is the list of predicted mention pairs\n","[[(anaphor_start, anaphor_end), (antecedent_start, antecedent_end)], ...] similar to draw_pairs in section 4."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F209Q1TSDHbD"},"outputs":[],"source":["def get_predicted_clusters(mention_pairs):\n","    mention_to_predicted = {}\n","    predicted_clusters = []\n","    \n","    # for each mention and its predicted antecedent\n","    for anaphora, predicted_antecedent in mention_pairs:\n","        # if the predicted antecedent has been processed before as an anaphor\n","        if predicted_antecedent in mention_to_predicted:\n","            # then the predicted cluster for the anaphor is the same as the one for its predicted antecedent\n","            predicted_cluster = mention_to_predicted[predicted_antecedent]\n","        # otherwise, \n","        else:\n","            # create a new cluster, with the antecedent as the first mention in that cluster\n","            predicted_cluster = len(predicted_clusters) # the cluster number (it's order in the list of clusters)\n","            predicted_clusters.append([predicted_antecedent])\n","            mention_to_predicted[predicted_antecedent] = predicted_cluster\n","\n","        # now we know the right cluster for the anaphor, add it to that cluster\n","        predicted_clusters[predicted_cluster].append(anaphora)\n","        mention_to_predicted[anaphora] = predicted_cluster\n","\n","    # make the cluster list a cluster tuple. Lists can be dictionary keys; they are mutable and support item assignment.\n","    predicted_clusters = [tuple(pc) for pc in predicted_clusters]\n","    # get the {mention: complete cluster} map for the predictions.\n","    mention_to_predicted = {m: predicted_clusters[i] for m, i in mention_to_predicted.items()}\n","\n","    return predicted_clusters, mention_to_predicted"]},{"cell_type":"markdown","metadata":{"id":"aLY8Wejt5wR_"},"source":["###**6.2 Coreference evaluation for a given document**\n","\n","In this subsection you will complete the `evaluate_coref()` function for coref evaluation on a single document. \n","\n","<br>\n","\n","The `evaluate_coref()` function takes 3 parameters:\n","* `predicted_mention_pairs`: the list of predicted mention pairs\n","* `gold_clusters`: the gold cluster from the orginal document\n","* `evaluator`: a reference to an instance of metrics.CorefEvaluator()\n","You will use the first 2 parameters to create variables to run the `evaluator.update()` method.\n","\n","<br>\n","\n","The`evaluator.update()` method takes 3 parameters:\n","* `predicted_clusters`: from 5.1\n","*  `gold_clusters`: the gold cluster from the orginal document, each cluster transformed from a list to a tuple.\n","* `mention_to_predicted`: from 5.1\n","* `mention_to_gold`: the gold equivalent of  `mention_to_predicted`\n","\n","<br>\n","\n","Some of the code has been written for you. You complete the code below to generate the rest of it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KC9CdNof-ZB8"},"outputs":[],"source":["def evaluate_coref(predicted_mention_pairs, gold_clusters, evaluator):\n","    \n","    # turn each cluster in the list of gold cluster into a tuple (rather than a list)\n","    gold_clusters = [tuple(tuple(mention) for mention in gc) for gc in gold_clusters] # TASK 3.1 CODE HERE\n","    \n","    # mention to gold is a {mention: cluster of mentions it belongs, including the present mention} map\n","    mention_to_gold = {}\n","    # TASK 3.2 WRITE CODE HERE TO GENERATE mention_to_gold from gold_clusters\n","    for gold_cluster in gold_clusters:\n","        for mention in gold_cluster:\n","            mention_to_gold[mention] = gold_cluster\n","\n","    # get the predicted_clusters and mention_to_predict using get_predicted_clusters()\n","    predicted_clusters, mention_to_predicted = get_predicted_clusters(predicted_mention_pairs)# TASK 3.3 CODE HERE\n","\n","    # run the evaluator using the parameters you've gotten\n","    evaluator.update(predicted_clusters, gold_clusters, mention_to_predicted, mention_to_gold)"]},{"cell_type":"markdown","metadata":{"id":"tzIvWQ39_FFS"},"source":["###**6.3 Evaluating the model on all the data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftA58laV50dS"},"outputs":[],"source":["def eval(model, eval_docs):\n","    coref_evaluator = metrics.CorefEvaluator()\n","\n","    for word_embeddings, mention_pairs, _, gold_clusters, raw_mention_pairs in eval_docs:\n","\n","        # get the mention pair scores from the model\n","        mention_pair_scores = model.predict_on_batch([word_embeddings, mention_pairs])\n","\n","        predicted_antecedents = {}\n","        best_antecedent_scores = {}\n","        # for a given anaphor \n","        for (ana, ant), score in zip(raw_mention_pairs, mention_pair_scores[0]):\n","            # only candidate antecedents with (ana, ante) above 0.5 are considered as valid system proposed candidates\n","            if score >= 0.5 and score > best_antecedent_scores.get(ana,0):\n","                # we chose the best among these to be the predicted antecedent for that anaphor\n","                predicted_antecedents[ana] = ant\n","                best_antecedent_scores[ana] = score\n","\n","        # getting the [anaphor, antecedent] pairs.\n","        predicted_mention_pairs = [[k,v] for k,v in predicted_antecedents.items()]\n","\n","        # evaluate the predicted mention pairs \n","        evaluate_coref(predicted_mention_pairs, gold_clusters, coref_evaluator)\n","\n","    # afer evaluating each document, get the conll prf\n","    p, r, f = coref_evaluator.get_prf()\n","    print(\"Average F1 (py): {:.2f}%\".format(f * 100))\n","    print(\"Average precision (py): {:.2f}%\".format(p * 100))\n","    print(\"Average recall (py): {:.2f}%\".format(r * 100))"]},{"cell_type":"markdown","metadata":{"id":"jnGTurMXuwd8"},"source":["##**7. Training and Evaluating the Model the Coreference Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYv_t2gPulH4"},"outputs":[],"source":["def time_used(start_time):\n","    curr_time = time.time()\n","    used_time = curr_time - start_time\n","    m = used_time // 60\n","    s = used_time - 60 * m\n","    return \"%d m %d s\" % (m, s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j0Y_H90D8XPi"},"outputs":[],"source":["def batch_generator(processed_data):\n","    random.shuffle(processed_data)\n","    for word_embeddings, mention_pairs, mention_pair_labels, _, _ in processed_data:\n","      yield [word_embeddings, mention_pairs], mention_pair_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4VcVF5k8V2A"},"outputs":[],"source":["def train(epochs):\n","    start_time = time.time()\n","    for epoch in range(epochs):\n","        print(\"\\nStarting training epoch {}/{}\".format(epoch + 1, epochs))\n","        epoch_time = time.time()\n","\n","        model.fit(batch_generator(TRAIN_DATA), steps_per_epoch=2775)\n","\n","        print(\"Time used for epoch {}: {}\".format(epoch + 1, time_used(epoch_time)))\n","        dev_time = time.time()\n","        print(\"Evaluating on dev set after epoch {}/{}:\".format(epoch + 1, epochs))\n","        eval(model, DEV_DATA)\n","        print(\"Time used for evaluate on dev set: {}\".format(time_used(dev_time)))\n","\n","    print(\"\\nTraining finished!\")\n","    print(\"Time used for training: {}\".format(time_used(start_time)))\n","\n","    print(\"\\nEvaluating on test set:\")\n","    test_time = time.time()\n","    eval(model, TEST_DATA)\n","    print(\"Time used for evaluate on test set: {}\".format(time_used(test_time)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlwLiXQUnM-V","executionInfo":{"status":"ok","timestamp":1651152022723,"user_tz":-60,"elapsed":1279800,"user":{"displayName":"amirsepehr aminian","userId":"07551957595912031317"}},"outputId":"54274fac-cd64-4853-f406-a612a595a30f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting training epoch 1/10\n","2775/2775 [==============================] - 331s 115ms/step - loss: 0.5611 - accuracy: 0.0000e+00\n","Time used for epoch 1: 5 m 30 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 18.98%\n","Average precision (py): 41.76%\n","Average recall (py): 13.21%\n","Time used for evaluate on dev set: 0 m 6 s\n","\n","Starting training epoch 2/10\n","2775/2775 [==============================] - 322s 116ms/step - loss: 0.4998 - accuracy: 0.0084\n","Time used for epoch 2: 5 m 22 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 31.24%\n","Average precision (py): 46.36%\n","Average recall (py): 26.47%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 3/10\n","2775/2775 [==============================] - 322s 115ms/step - loss: 0.4419 - accuracy: 0.0084\n","Time used for epoch 3: 5 m 21 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 43.36%\n","Average precision (py): 48.06%\n","Average recall (py): 47.19%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 4/10\n","2775/2775 [==============================] - 320s 115ms/step - loss: 0.4033 - accuracy: 0.0084\n","Time used for epoch 4: 5 m 20 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 47.88%\n","Average precision (py): 51.39%\n","Average recall (py): 50.57%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 5/10\n","2775/2775 [==============================] - 320s 115ms/step - loss: 0.3764 - accuracy: 0.0028\n","Time used for epoch 5: 5 m 20 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 48.24%\n","Average precision (py): 51.50%\n","Average recall (py): 53.65%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 6/10\n","2775/2775 [==============================] - 320s 115ms/step - loss: 0.3569 - accuracy: 0.0056\n","Time used for epoch 6: 5 m 20 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 48.73%\n","Average precision (py): 51.74%\n","Average recall (py): 55.10%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 7/10\n","2775/2775 [==============================] - 322s 116ms/step - loss: 0.3387 - accuracy: 0.0056\n","Time used for epoch 7: 5 m 21 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 51.03%\n","Average precision (py): 54.29%\n","Average recall (py): 56.89%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 8/10\n","2775/2775 [==============================] - 322s 116ms/step - loss: 0.3234 - accuracy: 0.0056\n","Time used for epoch 8: 5 m 21 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 49.07%\n","Average precision (py): 52.77%\n","Average recall (py): 58.03%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 9/10\n","2775/2775 [==============================] - 322s 116ms/step - loss: 0.3112 - accuracy: 0.0056\n","Time used for epoch 9: 5 m 21 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 50.64%\n","Average precision (py): 54.06%\n","Average recall (py): 56.88%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 10/10\n","2775/2775 [==============================] - 326s 117ms/step - loss: 0.2977 - accuracy: 0.0028\n","Time used for epoch 10: 5 m 25 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 49.23%\n","Average precision (py): 53.02%\n","Average recall (py): 58.87%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Training finished!\n","Time used for training: 54 m 27 s\n","\n","Evaluating on test set:\n","Average F1 (py): 46.57%\n","Average precision (py): 50.35%\n","Average recall (py): 58.02%\n","Time used for evaluate on test set: 0 m 4 s\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","# train the model for 10 epochs\n","train(10)"]},{"cell_type":"markdown","metadata":{"id":"O1gWNwkMSX8a"},"source":["##**8. Questions:**\n","\n","\n","\n","*   ### Would the performance decrease if we do not preprocess the text? If yes (or no), then why?\n","based on \"Anaphora Resolution with Real Preprocessing\" paper by Klener et al. . It is evident that the quality of preprocessing determines the quality of the rest, namely, the decision made by linguistic filters and the classification carried out by the machine learning classifier. Different preprocessing procedures effect the precision and recall which mean it would evntually effect f1 score. The reason for that is preprocessed versions lose some of the morphological features whithin the words and between them. \n","*   ### Experiment with different values for max antecedent (MAX_ANT) and negative ratio (NEG_RATIO), what do you observe?\n","We can see that how the different values effect the average f1 score.<br>\n","\n","|MAX_ANT  | NEG_Ratio | AVG F1(py)|\n","|-------------------|------------------|-----------------|\n","|250       | 2 | 46.32% |\n","|100       | 2 | 40.25% |\n","|400       | 2 | 40.38% |\n","|250       | 1 | 35.05% |\n","|250       | 3 | 45.49% |\n","|250       | 5 | 46.57% |\n","\n","The best result was for MaX_ENT of 250 and NEG_RATIO of 5. By my experiments there seems to be 250 is a reasonable value for MAX_ENT and increasing the NEG_RATIO would slightly increase the score.\n","\n","|EMBEDDING_DROPOUT_RATE  | AVG F! (py) | \n","|-------------------|------------------|\n","|0.2       | 42.22% |\n","|0.1       | 42.71% |\n","|0.0       | 43.36% |\n","|0.0 & NEG_RATIO = 4       | 45.86% |\n","|0.0 & NEG_RATIO = 5      | 46.57% |\n","\n","It seems that the model works best with 0 dropupot rate for embedding layers.\n","*   ### How would you improve the accuracy? \n","If we could add some more features before we feed the input to the neural network model it would be better. things like name entities. Also I think GRUs will work slightly better than LSTM here.\n","if the context here is important, we could try and make embeddings trainable so that it biases toward the context better.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfrHy1vo9RHq"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"7001_2021_22_Lab10_Coreference_Resolution_Student.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}